{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ANSWER =====\n",
      "\n",
      "The paper \"Attention Is All You Need\" introduces a novel neural network architecture called the Transformer, which relies entirely on attention mechanisms, eliminating the need for recurrent and convolutional layers that were prevalent in previous sequence transduction models. The key contributions of the paper include:\n",
      "\n",
      "1. **Attention Mechanism**: The Transformer utilizes an attention function that maps queries to key-value pairs, allowing the model to focus on different parts of the input sequence when generating outputs. This is achieved through a process that computes a weighted sum of the values based on the attention scores derived from the queries and keys.\n",
      "\n",
      "2. **Self-Attention**: The paper discusses self-attention, which enables the model to relate different positions within a single sequence, thereby capturing dependencies regardless of their distance in the sequence. This is particularly useful for tasks such as reading comprehension and summarization.\n",
      "\n",
      "3. **Multi-Head Attention**: The Transformer employs multi-head attention, which allows the model to attend to information from multiple representation subspaces simultaneously. This enhances the model's ability to capture diverse features and relationships within the data.\n",
      "\n",
      "4. **Efficiency**: The architecture is designed to be more efficient than traditional models, as it reduces the complexity of learning dependencies between distant positions in the input sequence. The use of attention mechanisms allows for constant time operations, making the model faster and more scalable.\n",
      "\n",
      "5. **Applications**: The Transformer architecture has been successfully applied to various natural language processing tasks, demonstrating its versatility and effectiveness in generating high-quality representations of sequences.\n",
      "\n",
      "Overall, \"Attention Is All You Need\" presents a significant advancement in the field of deep learning for sequence processing, highlighting the power of attention mechanisms in building more efficient and effective models.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "from typing import TypedDict, Sequence, List, Dict\n",
    "from typing_extensions import Annotated\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import Annotated\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --------------------------------------------------\n",
    "# ENV\n",
    "# --------------------------------------------------\n",
    "load_dotenv()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STATE\n",
    "# --------------------------------------------------\n",
    "class ResearchAgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    papers: List[dict]\n",
    "    query: str\n",
    "    extracted_info: dict\n",
    "    search_results: List[dict]\n",
    "    comparison_matrix: dict | None\n",
    "    research_gaps: List[str]\n",
    "    iteration_count: int\n",
    "    reflection: str\n",
    "    chunks: list\n",
    "    vectorstore: FAISS | None\n",
    "    reranked_docs: list\n",
    "    folder_path: str\n",
    "\n",
    "# --------------------------------------------------\n",
    "# NODES\n",
    "# --------------------------------------------------\n",
    "def load_pdfs(state: ResearchAgentState):\n",
    "    papers = []\n",
    "    for file in os.listdir(state[\"folder_path\"]):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(os.path.join(state[\"folder_path\"], file))\n",
    "            docs = loader.load()\n",
    "            papers.extend(docs)\n",
    "\n",
    "    return {\"papers\": papers}\n",
    "\n",
    "\n",
    "def split_documents(state: ResearchAgentState):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    chunks = splitter.split_documents(state[\"papers\"])\n",
    "    return {\"chunks\": chunks}\n",
    "\n",
    "\n",
    "def create_vectorstore(state: ResearchAgentState):\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "    vectorstore = FAISS.from_documents(state[\"chunks\"], embeddings)\n",
    "    return {\"vectorstore\": vectorstore}\n",
    "\n",
    "\n",
    "def retrieve_documents(state: ResearchAgentState):\n",
    "    docs = state[\"vectorstore\"].similarity_search(\n",
    "        state[\"query\"], k=10\n",
    "    )\n",
    "    return {\"search_results\": docs}\n",
    "\n",
    "\n",
    "def rerank_documents(state: ResearchAgentState):\n",
    "    reranker = CrossEncoder(\"BAAI/bge-reranker-base\")\n",
    "    pairs = [(state[\"query\"], doc.page_content) for doc in state[\"search_results\"]]\n",
    "    scores = reranker.predict(pairs)\n",
    "\n",
    "    reranked = sorted(\n",
    "        zip(state[\"search_results\"], scores),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    top_docs = [doc for doc, _ in reranked[:5]]\n",
    "    return {\"reranked_docs\": top_docs}\n",
    "\n",
    "\n",
    "def generate_answer(state: ResearchAgentState):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in state[\"reranked_docs\"]])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Answer the following research question using the provided context.\n",
    "\n",
    "Question:\n",
    "{state[\"query\"]}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response.content)],\n",
    "        \"reflection\": \"Answer generated using reranked evidence.\"\n",
    "    }\n",
    "\n",
    "# --------------------------------------------------\n",
    "# GRAPH\n",
    "# --------------------------------------------------\n",
    "graph = StateGraph(ResearchAgentState)\n",
    "\n",
    "graph.add_node(\"load_pdfs\", load_pdfs)\n",
    "graph.add_node(\"split_documents\", split_documents)\n",
    "graph.add_node(\"create_vectorstore\", create_vectorstore)\n",
    "graph.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "graph.add_node(\"rerank_documents\", rerank_documents)\n",
    "graph.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "graph.set_entry_point(\"load_pdfs\")\n",
    "\n",
    "graph.add_edge(\"load_pdfs\", \"split_documents\")\n",
    "graph.add_edge(\"split_documents\", \"create_vectorstore\")\n",
    "graph.add_edge(\"create_vectorstore\", \"retrieve_documents\")\n",
    "graph.add_edge(\"retrieve_documents\", \"rerank_documents\")\n",
    "graph.add_edge(\"rerank_documents\", \"generate_answer\")\n",
    "graph.add_edge(\"generate_answer\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# RUN\n",
    "# --------------------------------------------------\n",
    "initial_state: ResearchAgentState = {\n",
    "    \"folder_path\": \"C:/Users/sashi/OneDrive/Documents/langgraphProjects/researchPaper/papers\",\n",
    "    \"messages\": [],\n",
    "    \"papers\": [],\n",
    "    \"query\": input(\"Enter your research question: \"),\n",
    "    \"extracted_info\": {},\n",
    "    \"search_results\": [],\n",
    "    \"comparison_matrix\": None,\n",
    "    \"research_gaps\": [],\n",
    "    \"iteration_count\": 0,\n",
    "    \"reflection\": \"\",\n",
    "    \"chunks\": [],\n",
    "    \"vectorstore\": None,\n",
    "    \"reranked_docs\": []\n",
    "}\n",
    "\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n===== ANSWER =====\\n\")\n",
    "print(final_state[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what does attention is all you need tell about"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qaagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
